<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AI Voice Chat</title>
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap"
      rel="stylesheet"
    />
    <link href="/static/style.css" rel="stylesheet" />
  </head>
  <body>
    <div class="container">
      <h2>üé§ AI Voice Chat</h2>
      <div class="text" id="userText">(Push to Talk)</div>
      <div class="text" id="aiReply">Brian AI: Question me.</div>
      <button class="button" id="micBtn">Hold to Speak</button>
      <div class="loading" id="loading" style="display: none">Thinking...</div>
    </div>

    <script>
      let micBtn = document.getElementById("micBtn");
      let userText = document.getElementById("userText");
      let aiReply = document.getElementById("aiReply");
      let loading = document.getElementById("loading");
      let mediaRecorder,
        audioChunks = [];

      let naturalVoice = null;

      function loadVoices() {
        const voices = speechSynthesis.getVoices();

        console.log(speechSynthesis.getVoices());
        // ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏ü‡∏±‡∏á‡∏î‡∏π‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ (‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö OS/Browser)
        naturalVoice = voices.find(
          (v) => v.name.includes("Andrew") // v.name.includes("Google") ||
          // v.name.includes("Samantha") || v.name.includes("Alex") ||
          // v.name.includes("Microsoft") || v.name.includes("Zira") ||
          // v.name.includes("David") || v.name.includes("Microsoft Server") ||
          // v.name.includes("Microsoft Zira") || v.name.includes("Microsoft David") ||
          // v.lang === "en-US" || v.lang === "en-GB" ||
          // v.name.includes("Microsoft") ||
        );
      }

      // ‡∏ö‡∏≤‡∏á browser ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠‡πÉ‡∏´‡πâ voices ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡∏Å‡πà‡∏≠‡∏ô
      if (speechSynthesis.onvoiceschanged !== undefined) {
        speechSynthesis.onvoiceschanged = loadVoices;
      }

      // ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á desktop (mouse) ‡πÅ‡∏•‡∏∞ mobile (touch)
      function startRecording() {
        if (micBtn.disabled) return;

        userText.innerHTML = `Listening`;
        navigator.mediaDevices.getUserMedia({ audio: true }).then((stream) => {
          // ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ö‡∏ô iOS/Safari
          let options = { audioBitsPerSecond: 128000 };

          if (MediaRecorder.isTypeSupported("audio/mp4")) {
            options.mimeType = "audio/mp4"; // ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Safari/iOS
          } else if (MediaRecorder.isTypeSupported("audio/webm;codecs=opus")) {
            options.mimeType = "audio/webm;codecs=opus";
          } else {
            options.mimeType = "audio/webm";
          }

          mediaRecorder = new MediaRecorder(stream, options);
          audioChunks = [];

          mediaRecorder.ondataavailable = (e) => {
            if (e.data.size > 0) {
              audioChunks.push(e.data);
            }
          };

          mediaRecorder.onstop = async () => {
            micBtn.disabled = true;
            micBtn.classList.remove("recording");
            loading.style.display = "block";

            const blob = new Blob(audioChunks, {
              type: mediaRecorder.mimeType,
            });
            const formData = new FormData();
            formData.append(
              "file",
              blob,
              `audio.${getExtension(mediaRecorder.mimeType)}`
            );

            try {
              // STEP 1: ‡∏™‡πà‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏õ‡πÉ‡∏´‡πâ whisper ‡∏ó‡∏µ‡πà backend
              const res = await fetch("/transcribe", {
                method: "POST",
                body: formData,
              });
              const data = await res.json();
              const transcript = data.transcript?.trim();

              if (!transcript) {
                userText.innerHTML = "You: <em>(no voice recognized)</em>";
                micBtn.disabled = false;
                loading.style.display = "none";
                return;
              }

              userText.innerHTML = `You: <strong>${transcript}</strong>`;

              // STEP 2: ‡∏™‡πà‡∏á transcript ‡πÑ‡∏õ‡∏´‡∏≤ AI chat
              const chatForm = new FormData();
              chatForm.append("message", transcript);
              const chatRes = await fetch("/chat", {
                method: "POST",
                body: chatForm,
              });
              const chatData = await chatRes.json();

              const utterance = new SpeechSynthesisUtterance(chatData.reply);
              utterance.lang = "en-US";
              utterance.rate = 1;
              utterance.pitch = 1;

              // ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°
              if (naturalVoice) {
                utterance.voice = naturalVoice;
              } else {
                loadVoices();
                const voices = speechSynthesis.getVoices();
                utterance.voice =
                  voices.find((v) => v.lang.includes("en")) || voices[0];
              }

              speechSynthesis.speak(utterance);

              aiReply.innerHTML = `AI: ${chatData.reply}`;
            } catch (error) {
              console.error("Error:", error);
              userText.innerHTML = "Error occurred";
              aiReply.innerHTML = "Please try again";
            } finally {
              micBtn.disabled = false;
              loading.style.display = "none";
            }
          };

          micBtn.classList.add("recording");
          mediaRecorder.start();
        });
      }

      function stopRecording() {
        if (mediaRecorder && mediaRecorder.state === "recording") {
          mediaRecorder.stop();
        }
      }

      // Desktop
      micBtn.addEventListener("mousedown", startRecording);
      micBtn.addEventListener("mouseup", stopRecording);

      // Mobile
      micBtn.addEventListener("touchstart", (e) => {
        e.preventDefault(); // ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£ select/copy
        startRecording();
      });

      micBtn.addEventListener("touchend", (e) => {
        e.preventDefault(); // ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£ select/copy
        stopRecording();
      });

      // ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç event listeners for iOS
      micBtn.addEventListener("pointerdown", startRecording);
      micBtn.addEventListener("pointerup", stopRecording);
      micBtn.addEventListener("touchcancel", stopRecording); // ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö iOS

      // ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏¢‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å MIME type
      function getExtension(mimeType) {
        if (mimeType.includes("mp4")) return "mp4";
        if (mimeType.includes("webm")) return "webm";
        return "wav";
      }
    </script>
  </body>
</html>
